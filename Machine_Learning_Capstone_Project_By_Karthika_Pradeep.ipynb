{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthikamanu123/Capstone-Project-6--ML/blob/main/Machine_Learning_Capstone_Project_By_Karthika_Pradeep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Health Insuarance Cross Sell Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -** Health Insuarance Cross Sell Prediction\n"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective: This project aims to develop a predictive model that will significantly enhance the effectiveness of marketing campaigns for additional vehicle insurance. By accurately identifying customers who are most likely to be interested in these products, the insurance company can optimize resource allocation, improve customer satisfaction, and drive revenue growth."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -** https://github.com/karthikamanu123/Capstone-Project-6--ML.git"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project aims to develop a machine learning model to predict the likelihood of customers purchasing additional vehicle insurance based on their demographic, vehicle, insurance, and interaction data. This model will help the insurance company optimize marketing efforts, improve customer retention, and increase revenue."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Visualisation libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Data Preprocessing libraries\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ML models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.metrics import accuracy_score, recall_score, classification_report, precision_score, f1_score, ConfusionMatrixDisplay\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "health_insurance_data=pd.read_csv('/content/TRAIN-HEALTH INSURANCE CROSS SELL PREDICTION.csv')"
      ],
      "metadata": {
        "id": "Ba7CtC0xzycQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "health_insurance_data.shape"
      ],
      "metadata": {
        "id": "Buk5hb-M2mje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = health_insurance_data.copy()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "data.head()"
      ],
      "metadata": {
        "id": "aI5hOSk90Fyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "count_of_rows= data.shape[0]\n",
        "count_of_columns= data.shape[1]\n",
        "print(f\"Number_of_rows:{count_of_rows}\")\n",
        "print(f\"Number_of_columns:{count_of_columns}\")"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "data.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "no_of_duplicated_values=data.duplicated().sum()\n",
        "print(f\"Number of duplicaled values:{no_of_duplicated_values}\")"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.heatmap(data.isnull())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset comprises 12 features and 381,109 instances, with no missing or duplicate values."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "data.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**id**: Unique ID for the customer.\n",
        "\n",
        "**Gender**: Gender of the customer (Male/Female).\n",
        "\n",
        "**Age**: Age of the customer.\n",
        "\n",
        "**Driving License**: Indicates if the customer has a driving license (DL) or not.\n",
        "\n",
        "**Region_Code**: Unique code for the region of the customer.\n",
        "\n",
        "**Previously_insured**: Whether the customer already has vehicle insurance or not.\n",
        "\n",
        "**Vehicle_age**: Age of the vehicle.\n",
        "\n",
        "**Vehicle_damage**: Indicates if the vehicle has past damages or not.\n",
        "\n",
        "**Annual_premium**: The amount the customer needs to pay as a premium.\n",
        "\n",
        "**PolicySalesChannel**: Anonymized code for the channel used to reach out to the customer (e.g., Different Agents, Over Mail, Over Phone, In Person, etc.).\n",
        "\n",
        "**Vintage**: Number of days the customer has been associated with the company.\n",
        "\n",
        "**Response**: Indicates if the customer is interested or not."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "data.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Chnage Data Types of column\n",
        "data['Region_Code'] = data['Region_Code'].astype('str')\n",
        "data['Policy_Sales_Channel'] = data['Policy_Sales_Channel'].astype('int').astype('str')"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Separate Numerical and categorical columns from a dataset\n",
        "\n",
        "Categorical_columns = [column for column in data.columns if data[column].dtype == 'object']\n",
        "Numerical_columns = [column for column in data.columns if data[column].dtype != 'object']\n",
        "\n",
        "Continuous_columns = [column for column in Numerical_columns if len(data[column].unique()) > 20]\n",
        "Discrete_columns = [column for column in Numerical_columns if len(data[column].unique()) < 20]\n",
        "\n",
        "\n",
        "print(f'Categrical Columns: {Categorical_columns}')\n",
        "print(f'Numerical Columns: {Numerical_columns}')\n",
        "print(\"Continuous Columns:\", Continuous_columns)\n",
        "print(\"Discrete Columns:\", Discrete_columns)"
      ],
      "metadata": {
        "id": "_36MJ0Id62Ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function called Age so that we can categorize age in to different age groups\n",
        "def age_range(age):\n",
        "    \"\"\"\n",
        "    Categorize a given age into a descriptive age range.\n",
        "\n",
        "    Parameters:\n",
        "    age (int or float): The age to categorize.\n",
        "\n",
        "    Returns:\n",
        "    str: A string representing the age range.\n",
        "         'Young' for ages less than 30,\n",
        "         'Middle Age' for ages between 30 and 50 (inclusive),\n",
        "         'Old' for ages greater than 50.\n",
        "    \"\"\"\n",
        "    if age < 30:\n",
        "        return 'Young'\n",
        "    elif 30 <= age <= 50:\n",
        "        return 'Middle Age'\n",
        "    else:\n",
        "        return 'Old'"
      ],
      "metadata": {
        "id": "nQjT3mNJjKDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a new column called Age_Group\n",
        "data['Age_Group'] = data['Age'].apply(age_range)"
      ],
      "metadata": {
        "id": "diKRziP5joOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking for new column\n",
        "data.columns"
      ],
      "metadata": {
        "id": "r2Yb2pBJkAN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom func that takes column as an input and give the basic summary stats\n",
        "def summary_stats(columns : list, data : pd.DataFrame) -> pd.DataFrame:\n",
        "  '''\n",
        "    This function takes a list of column names and a DataFrame as inputs, and returns basic\n",
        "    statistics for each specified column. Statistics include:\n",
        "    - Mode\n",
        "    - Mean\n",
        "    - Median\n",
        "    - Standard Deviation\n",
        "    - Variance\n",
        "    - First Quartile (Q1)\n",
        "    - Third Quartile (Q3)\n",
        "    - Interquartile Range (IQR)\n",
        "    - Range\n",
        "    - Outlier Upper Bound\n",
        "    - Outlier Lower Bound\n",
        "\n",
        "    Parameters:\n",
        "    columns (list): List of column names to calculate statistics for.\n",
        "    data (pd.DataFrame): DataFrame containing the data.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: DataFrame containing the calculated statistics.\n",
        "    '''\n",
        "  # Calculate the stats\n",
        "  stats = {}\n",
        "  for column in columns:\n",
        "    if pd.api.types.is_numeric_dtype(data[column]):\n",
        "      try:\n",
        "        mean = np.round(data[column].mean(), 2)\n",
        "      except:\n",
        "        mean = np.nan\n",
        "      try:\n",
        "        std = np.round(data[column].std(), 2)\n",
        "      except:\n",
        "        std = np.nan\n",
        "      try:\n",
        "        var = np.round(data[column].var(), 2)\n",
        "      except:\n",
        "        var = np.nan\n",
        "    else:\n",
        "      try:\n",
        "        mean = data[column].mean()\n",
        "      except:\n",
        "        mean = np.nan\n",
        "      try:\n",
        "        std = data[column].std()\n",
        "      except:\n",
        "        std = np.nan\n",
        "      try:\n",
        "        var = data[column].var()\n",
        "      except:\n",
        "        var = np.nan\n",
        "\n",
        "    try:\n",
        "      q25 = data[column].quantile(0.25)\n",
        "    except:\n",
        "      q25 = np.nan\n",
        "    try:\n",
        "      median = data[column].median()\n",
        "    except:\n",
        "      median = np.nan\n",
        "    try:\n",
        "      mode = data[column].mode()[0]\n",
        "    except:\n",
        "      mode = np.nan\n",
        "    try:\n",
        "      q75 = data[column].quantile(0.75)\n",
        "    except:\n",
        "      q75 = np.nan\n",
        "    try:\n",
        "      max_val = data[column].max()\n",
        "    except:\n",
        "      max_val = np.nan\n",
        "    try:\n",
        "      min_val = data[column].min()\n",
        "    except:\n",
        "      min_val = np.nan\n",
        "    try:\n",
        "      iqr = q75 - q25\n",
        "    except:\n",
        "      iqr = np.nan\n",
        "    try:\n",
        "      out_upperbound = q75 + 1.5 * iqr\n",
        "    except:\n",
        "      out_upperbound = np.nan\n",
        "    try:\n",
        "      out_lowerbound = q25 - 1.5 * iqr\n",
        "    except:\n",
        "      out_lowerbound = np.nan\n",
        "    try:\n",
        "      range_val = max_val - min_val\n",
        "    except:\n",
        "      range_val = np.nan\n",
        "\n",
        "    try:\n",
        "      percentage_outlier = np.round((data[(data[column] > out_upperbound) | (data[column] < out_lowerbound)].shape[0] / data.shape[0]) * 100, 2)\n",
        "    except:\n",
        "      percentage_outlier = np.nan\n",
        "\n",
        "      # Create a Dict\n",
        "    stats_dict = {'Mean': mean, 'Median': median,\n",
        "                  'Std': std, 'Variance':var,\n",
        "                    \"First Quartile\":q25, \"Third Quartile\":q75,\n",
        "                    \"IQR\":iqr, \"Range\":range_val,\n",
        "                    \"Outlier Upper-Bound\":out_upperbound,\n",
        "                    \"Outlier Lower-Bound\":out_lowerbound,\n",
        "                    \"Percentage Outlier\": percentage_outlier}\n",
        "    stats[column] = stats_dict\n",
        "\n",
        "\n",
        "\n",
        "  # Create a DataFrame\n",
        "  stats_df = pd.DataFrame(stats)\n",
        "\n",
        "  return stats_df.T"
      ],
      "metadata": {
        "id": "FhGsrsTpkJyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_summary = summary_stats(Continuous_columns, data)\n",
        "data_summary"
      ],
      "metadata": {
        "id": "l7dsYX9ykjtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above data we can see that Annual_Premium column has so many outliers"
      ],
      "metadata": {
        "id": "Gre55APMlTQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of outliers in Annual_Premium column\n",
        "sns.boxplot(data['Annual_Premium'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t67pceO_lwHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above figure it is clear that,The Annual_Premium column exhibits a highly skewed distribution with a long right tail. This indicates that while most policies have lower premiums, there are a significant number of policies with much higher premiums, likely due to factors like coverage level, vehicle type, or risk profile."
      ],
      "metadata": {
        "id": "VLJmo34SmXu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "upper_bound =  data_summary.iloc[2, 8]\n",
        "lower_bound =  data_summary.iloc[2, 9]\n",
        "outlier_value = data[(data['Annual_Premium'] > upper_bound) | (data['Annual_Premium'] < lower_bound)]['Annual_Premium']\n",
        "outlier_value"
      ],
      "metadata": {
        "id": "qVANozzfmvvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the Annual_Premium column, there are 10320 outliers, accounting for approximately 2.71% of the dataset. While the causes of these outliers could be varied and should be carefully considered before addressing them, for the purposes of this project, we will just drop the outliers as it is just 2.71% of the eniter dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "Q8CgikWc_T9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = data[(data['Annual_Premium'] < upper_bound) & (data['Annual_Premium'] > lower_bound)]"
      ],
      "metadata": {
        "id": "e2rxWkEQ_gp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "TiN_ldlK_osh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Cast 'Region Code' and 'Policy Sales Channel' as categorical variables.\n",
        "*  Categorized customers into age groups: 'Young' (under 30), 'Middle Age' (30-50), and 'Old' (over 50).\n",
        "\n",
        "*   Implemented a custom function for descriptive analysis.\n",
        "\n",
        "*   Identified and quantified outliers using the Interquartile Range (IQR) method.\n",
        "\n",
        "*   Removed outliers in the 'Annual Premium' column, affecting approximately 2.71% of the dataset.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "plt.figure(figsize=(15, 7))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(df['Age'], bins=25, kde=True, color='g')\n",
        "\n",
        "mean_age = df['Age'].mean()\n",
        "# Add a vertical line at the mean\n",
        "plt.axvline(mean_age, color='r', linestyle='--', linewidth=2, label=f'Mean: {mean_age:.2f}')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Counts')\n",
        "plt.title('Distribution of Age')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(data = df, x='Age', bins=25, kde=True, hue='Gender',  palette=['purple', 'orange'])\n",
        "\n",
        "mean_age_male = df[df['Gender'] == 'Male']['Age'].mean()\n",
        "mean_age_female = df[df['Gender'] == 'Female']['Age'].mean()\n",
        "plt.axvline(mean_age_male, color='b', linestyle='--', linewidth=2)\n",
        "plt.axvline(mean_age_female, color='r', linestyle='--', linewidth=2)\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Counts')\n",
        "plt.title('Distribution of Age By Gender')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The choice of a histogram with a density curve and vertical lines for the mean provides a clear visual representation of the age distribution and its central tendency. This allows for easy comparison and interpretation of the data, both overall and when considering gender differences."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Both the overall age distribution and the distributions for males and females are right-skewed. This means that the majority of individuals in the dataset are younger, with a smaller number of older individuals.\n",
        "*   The overall mean age is approximately 38.67 years, indicating that the average age of individuals in the dataset is around 38.\n",
        "\n",
        "*  The mean age for males is slightly higher than the overall mean, around 41 years.\n",
        "\n",
        "* The mean age for females is lower than the overall mean, around 36 years.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, by understanding these age and gender trends, the business can optimize operations, improve customer satisfaction, and drive revenue growth."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "\n",
        "plt.figure(figsize=(15, 7))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "sns.histplot(data=df, x='Annual_Premium', bins=25, kde=True)\n",
        "plt.xlabel('Annual_Premium')\n",
        "plt.ylabel('Counts')\n",
        "plt.title('Distribution of Annual Premium')\n",
        "plt.grid(True, linestyle='--', alpha=0.3)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.histplot(data=df, x='Annual_Premium', bins=25, kde=True,  hue='Gender')\n",
        "plt.xlabel('Annual_Premium')\n",
        "plt.ylabel('Counts')\n",
        "plt.title('Distribution of Annual Premium By Gender')\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The histograms with density curves provide a clear visual representation of the distribution of annual premiums. This allows for easy comparison and interpretation of the data, both overall and when considering gender differences."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Both the overall distribution and the gender-specific distributions exhibit a right-skewed pattern. This indicates that a majority of policies have lower annual premiums, while a smaller portion of policies have significantly higher premiums.\n",
        "*   The overall shape and spread of the distributions for males and females appear to be quite similar. This suggests that the factors influencing annual premiums might not be significantly different between genders.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Absolutely, the insights gained from the chart can significantly contribute to positive business impact.Some of the positive impacts are:\n",
        "\n",
        "\n",
        "*   We can Optimize Pricing Strategies\n",
        "*   Improve Customer Segmentation\n",
        "\n",
        "*  Enhance Customer Satisfaction\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "sns.histplot(data=df, x='Vintage', kde=True, bins=25)\n",
        "plt.xlabel('Vintage')\n",
        "plt.ylabel('Counts')\n",
        "plt.title('Distribution of Vintage')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " The histogram with a density curve provides a comprehensive and informative visualization of the \"Vintage\" variable, making it a valuable tool for data exploration and analysis.Also it provides a clear visual representation of the frequency distribution of the data."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The distribution of \"Vintage\" appears to be relatively uniform, indicating that there is no significant bias towards any particular value. This suggests that the data is evenly distributed across the range.\n",
        "\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the insights gained from the chart can definitely help create a positive business impact.Some of them are;\n",
        "\n",
        "\n",
        "*   By analyzing vintage, businesses can segment customers based on their tenure and tailor marketing campaigns accordingly.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each gender in the 'Gender' column of the DataFrame 'df'\n",
        "gender_count = df['Gender'].value_counts().reset_index()\n",
        "\n",
        "# Rename the columns of the resulting DataFrame for clarity\n",
        "gender_count.columns = ['Gender', 'Count']\n",
        "\n",
        "# Display the DataFrame containing the gender counts\n",
        "print(gender_count)\n"
      ],
      "metadata": {
        "id": "sjyTRXJ2zllf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "plt.pie(gender_count['Count'], labels=gender_count['Gender'], autopct='%1.1f%%', startangle=90, shadow=True,\n",
        "        colors= ['#66b3ff','#FFC0CB'],\n",
        "        textprops={'fontweight':'bold'})\n",
        "plt.title('Gender Distribution')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pie chart illustrates the gender distribution, revealing a slight male predominance. Males constitute 54% of the total, while females account for 46%."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main insights from the chrt are;\n",
        "\n",
        "\n",
        "*   The gender distribution shows that males constitute a larger portion (54.0%) compared to females (46.0%) in the dataset.\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the insights from the pie chart can definitely help create a positive business impact.Some of the posiive insights are:\n",
        "\n",
        "\n",
        "*  By understanding the gender distribution, businesses can tailor marketing campaigns to specific demographics.\n",
        "*  Businesses can develop products or services that cater to the specific needs and preferences of each gender.\n",
        "\n"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average annual premium for each gender group in the DataFrame 'df'\n",
        "gender_annual = df.groupby(['Gender'])['Annual_Premium'].mean().reset_index()\n",
        "print(gender_annual)"
      ],
      "metadata": {
        "id": "FjnE1ud_3h2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "\n",
        "# Create the figure and axes\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
        "sns.barplot(x=gender_annual['Gender'], y=gender_annual['Annual_Premium'],  hue=gender_annual['Gender'], palette = 'bright',ax=ax)\n",
        "ax.set_title('Annual Premium',color='#005ce6', fontweight='bold')\n",
        "\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container,color='black', fontweight='bold')\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart is the most appropriate choice for visualizing the annual premium by gender as it provides a clear and concise comparison of the average values for each category."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the bar chart, we can observe the following key insights:\n",
        "\n",
        "\n",
        "*   The chart indicates that there is a negligible difference between the average annual premium for males and females.\n",
        "*   The data suggests that there is no significant gender-based pricing difference in the insurance premiums. Both genders seem to be charged similar rates, on average.\n",
        "\n"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the insights gained from the chart can definitely help create a positive business impact.Some of them are:\n",
        "\n",
        "\n",
        "*   By recognizing that there's no significant difference in average annual premiums between genders, insurance companies can ensure fair pricing practices.\n",
        "*   This can enhance customer trust and loyalty by demonstrating a commitment to equitable pricing\n",
        "\n",
        "*   By understanding customer preferences and behaviors, regardless of gender, companies can offer personalized products and services.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average annual premium for each vehicle age group in the DataFrame 'df'\n",
        "\n",
        "vehical_age_premium = df.groupby(['Vehicle_Age'])['Annual_Premium'].mean().reset_index()\n",
        "print(vehical_age_premium)"
      ],
      "metadata": {
        "id": "YXNjWu-j-bbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Create the figure and axes\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
        "sns.barplot(x=vehical_age_premium['Vehicle_Age'], y=vehical_age_premium['Annual_Premium'],  hue=vehical_age_premium['Vehicle_Age'], palette = 'mako',ax=ax)\n",
        "ax.set_title('Annual Premium',color='#005ce6', fontweight='bold')\n",
        "\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container,color='black', fontweight='bold')\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a bar chart to visualize the annual premium by vehicle age because it's an effective way to compare discrete categories (vehicle age groups) and their corresponding numerical values (annual premium)"
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By analyzing the bar chart, we can identify the following key insights:\n",
        "\n",
        "*   The chart clearly demonstrates that the average annual premium varies significantly based on the vehicle's age.\n",
        "*  As the vehicle age increases, the average annual premium tends to rise. This suggests that older vehicles are generally associated with higher insurance costs.\n",
        "\n"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the gained insights can significantly contribute to a positive business impact for an insurance company.\n",
        "\n",
        "Some of the insights are:\n",
        "\n",
        "\n",
        "*   By understanding the correlation between vehicle age and risk, insurance companies can implement more accurate risk-based pricing models.\n",
        "*   Insurance companies can develop specialized insurance products that cater to the specific needs of owners of older or newer vehicles.\n",
        "\n",
        "*   By understanding the unique needs of different age groups, companies can deliver personalized messages and improve customer engagement.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each response category (0 and 1) in the 'Response' column\n",
        "response_count = df['Response'].value_counts().reset_index()\n",
        "response_count.columns = ['Response', 'Count']\n",
        "response_count['Response'] = response_count['Response'].map({0:'Not Intrested', 1:'Intrested'})\n",
        "response_count"
      ],
      "metadata": {
        "id": "Gw0uu1sHF9QJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "plt.pie(response_count['Count'], labels=response_count['Response'], autopct='%1.1f%%', startangle=90, shadow=True,\n",
        "        colors=['#ff9999','#66b3ff'],\n",
        "        textprops={'fontweight':'bold'})\n",
        "plt.title('Response Distribution')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a pie chart to visualize the response distribution because it is an effective way to show the proportion of each category (interested and not interested) relative to the total."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main insights are:\n",
        "\n",
        "\n",
        "*  The pie chart reveals that only a small percentage (12.2%) of individuals expressed interest in the product or service.\n",
        "*   The majority of respondents (87.8%) showed disinterest, indicating a significant lack of appeal or relevance.\n",
        "\n"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the insights gained from the pie chart can definitely help create a positive business impact.Some of the positive impacts are:\n",
        "\n",
        "*   By understanding the reasons for disinterest, businesses can identify specific shortcomings in their offerings\n",
        "*   This enables them to make necessary improvements to increase appeal and meet customer needs.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# Set up the figure size\n",
        "plt.figure(figsize=(15, 7))\n",
        "\n",
        "# Plot 1: Gender vs Annual Premium\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.boxplot(data=df, x='Age_Group', y='Annual_Premium', palette='mako')\n",
        "plt.xlabel('Age Group')\n",
        "plt.ylabel('Annual Premium')\n",
        "plt.grid(True, alpha=0.5)  # Add grid with alpha\n",
        "\n",
        "# Plot 2: Vehicle Age vs Annual Premium\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.boxplot(data=df, x='Vehicle_Age', y='Annual_Premium', palette='mako')\n",
        "plt.xlabel('Vehicle Age')\n",
        "plt.ylabel('Annual Premium')\n",
        "plt.grid(True, alpha=0.5)  # Add grid with alpha\n",
        "\n",
        "# Plot 3: Vehicle Damage vs Annual Premium\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.boxplot(data=df, x='Vehicle_Damage', y='Annual_Premium', palette='mako')\n",
        "plt.xlabel('Vehicle Damage')\n",
        "plt.ylabel('Annual Premium')\n",
        "plt.grid(True, alpha=0.5)  # Add grid with alpha\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the plots\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boxplots are an excellent choice for visualizing the distribution of numerical data, especially when you want to compare multiple groups or categories. Boxplots provide a clear visual summary of the central tendency, spread, and potential outliers for each category, helping to identify trends and variations in premiums across these factors."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights found from the charts are:\n",
        "\n",
        "\n",
        "*  The annual premium distribution is right-skewed for all categories, indicating that there are a significant number of policies with higher premiums compared to the majority.\n",
        "*  Older vehicles tend to have higher premiums\n",
        "\n",
        "*  The whiskers for the \"Young\" age group are longer than the other two groups, suggesting more variability in premiums for this category.\n",
        "*   Newer vehicles (< 1 year) have the lowest premiums\n",
        "\n",
        "*   Vehicles with damage have significantly higher premiums:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the gained insights can definitely help create a positive business impact in various ways  they are:\n",
        "\n",
        "\n",
        "*   Based on vehicle age and damage, the company can implement a tiered pricing strategy to optimize revenue and attract customers.\n",
        "*  Offer discounts to customers with newer vehicles or those without damage to incentivize them.\n",
        "\n",
        "*  Identify high-risk segments (older vehicles, vehicles with damage) and adjust premiums accordingly\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Counts the occurrences of each response within each gender category\n",
        "gender_response_count = df.groupby('Gender')['Response'].value_counts().reset_index(name='Count')\n",
        "gender_response_count\n"
      ],
      "metadata": {
        "id": "OXnH7C3UK1eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "plt.figure(figsize=(10,7))\n",
        "ax = sns.countplot(data=df, x='Gender', hue='Response', palette='pastel')\n",
        "ax.set_title('Gender vs Response',color='#005ce6', fontweight='bold')\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container,color='black', fontweight='bold')\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The stacked bar chart is a suitable choice for this data as it provides a clear and concise visualization of the response counts by gender and the distribution of responses within each gender group."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the stacked bar chart, we can observe the following insights:\n",
        "\n",
        "\n",
        "*   A significantly higher number of males responded compared to females.\n",
        "*   While the overall response count is lower for females, the distribution of responses between categories 0 and 1 is relatively similar to males\n",
        "\n",
        "*   Females have a higher count of \"Not Interested\" responses (152,871) compared to \"Interested\" responses (17,599).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the gained insights can certainly help create a positive business impact.\n",
        "\n",
        "Here are some positive insights:\n",
        "\n",
        "\n",
        "*   By understanding the response patterns of different genders, businesses can tailor marketing campaigns to resonate with specific demographics.\n",
        "*   By understanding how different genders interact with products, businesses can optimize user experience for both groups.\n",
        "\n",
        "*    By analyzing the data, businesses can predict future trends and potential risks, allowing them to take proactive measures.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculates the average annual premium for each age group.\n",
        "age_group_premium = df.groupby('Age_Group')['Annual_Premium'].mean().reset_index()\n",
        "age_group_premium"
      ],
      "metadata": {
        "id": "pOZQS9dJNVQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "# Create the figure and axes\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
        "sns.barplot(x=age_group_premium['Age_Group'], y=age_group_premium['Annual_Premium'],  hue=age_group_premium['Age_Group'], palette = 'deep', ax=ax)\n",
        "ax.set_title('Annual Premium',color='#005ce6', fontweight='bold')\n",
        "\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container,color='black', fontweight='bold')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart is a simple, effective, and visually appealing way to compare the mean annual premium across different age groups."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights are:\n",
        "\n",
        "\n",
        "*    The middle age group has the lowest average annual premium compared to other age groups.\n",
        "*  The old age group has a higher average annual premium compared to the middle age group.\n",
        "\n",
        "*  The young age group has the highest average annual premium.\n",
        "*  There seems to be a general trend of increasing annual premium with increasing age.\n",
        "\n"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the gained insights can definitely help create a positive business impact.Some of them are:\n",
        "\n",
        "\n",
        "*    Based on age groups, the company can implement a tiered pricing strategy to optimize revenue and attract customers\n",
        "*  Offer discounts to specific age groups to incentivize them.\n",
        "\n",
        "*   Create targeted marketing campaigns for different age groups.\n",
        "\n",
        "*    Offer personalized discounts, promotions, or add-on services to specific age groups.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "# Create a scatter plot of Annual Premium vs Vintage, with points colored by Gender\n",
        "sns.scatterplot(data=df, y='Vintage', x='Annual_Premium', hue='Gender')\n",
        "\n",
        "# Set the title of the plot with bold formatting\n",
        "plt.title('Annual Premium vs Vintage', fontweight='bold')\n",
        "\n",
        "# Set the x-axis label with bold formatting\n",
        "plt.xlabel('Annual Premium', fontweight='bold')\n",
        "\n",
        "# Set the y-axis label with bold formatting\n",
        "plt.ylabel('Vintage', fontweight='bold')\n",
        "\n",
        "# Position the legend in the upper right corner\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A scatter plot is an excellent choice for this dataset because it helps visualize the relationship between two numerical variables they are; Annual Premium and Vintage."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the scatter plot, we can observe the following insights:\n",
        "\n",
        "*   There doesn't seem to be a strong linear relationship between the annual premium and vintage.\n",
        "*  The points are scattered randomly across the plot, indicating that the premium doesn't increase or decrease consistently with the vintage.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the gained insights from the scatter plot can definitely help create a positive business impact.Some of them are:\n",
        "\n",
        "*   The company can ensure fair pricing by not solely relying on policy vintage to determine premiums.\n",
        "*   By analyzing other factors like claim history, customer loyalty, and policy add-ons, the company can identify high-value customers and tailor offers to retain them.\n",
        "\n",
        "*  The company can target specific customer segments with personalized offers based on their needs and preferences.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Groups the data by 'Region_Code' and calculates the count of IDs and mean annual premium for each group.\n",
        "# Sorts the groups by the count of IDs in descending order and selects the top 10 regions.\n",
        "top_10_region = df.groupby('Region_Code').agg({'id': 'count', 'Annual_Premium': 'mean'}).sort_values(by='id', ascending=False)[:10]\n",
        "top_10_region.columns = ['Count', 'Annual_Premium']\n",
        "top_10_region"
      ],
      "metadata": {
        "id": "nmMu6d2FWgKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "# Create a horizontal bar plot\n",
        "top_10_region.plot(kind='barh', figsize=(10, 6))\n",
        "\n",
        "# Set the x-axis label with bold formatting\n",
        "plt.xlabel('Count', fontweight='bold')\n",
        "\n",
        "# Set the y-axis label with bold formatting\n",
        "plt.ylabel('Region', fontweight='bold')\n",
        "\n",
        "# Set the title of the plot with bold formatting\n",
        "plt.title('Top 10 Region by Count', fontweight='bold')\n",
        "\n",
        "plt.grid(True, alpha=0.5)  # Add grid with alpha\n",
        "\n",
        "plt.gca().invert_yaxis()  # Invert the y-axis to display the highest count at the top\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A horizontal bar chart is a visually effective way to compare and rank the top 10 regions based on the number of policies and their average annual premiums."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the horizontal bar chart, we can observe the following insights:\n",
        "\n",
        "\n",
        "*   Region 28.0 has the highest number of policies, indicating it's a significant market for the insurance company.\n",
        "*   The number of policies varies significantly across different regions, suggesting varying market penetration and customer base.\n",
        "\n",
        "*   The average annual premium varies across regions. Some regions have higher average premiums, while others have lower ones.\n",
        "*   Factors like demographics, economic conditions, and risk profiles of customers in different regions might influence the average premium.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the gained insights can definitely help create a positive business impact.Some of them are:\n",
        "\n",
        "\n",
        "*    By understanding the average premium and customer base in each region, the company can offer personalized deals and promotions.\n",
        "*   The company can allocate resources, such as sales and support teams, to regions with higher potential and growth opportunities.\n",
        "\n",
        "*    The company can tailor marketing campaigns to specific regions based on their unique characteristics.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Groups the data by 'Policy_Sales_Channel' and calculates the count of IDs and mean annual premium for each channel\n",
        "top_10_policy_channel = df.groupby('Policy_Sales_Channel').agg({'id': 'count', 'Annual_Premium': 'mean'}).sort_values(by='id', ascending=False)[:10]\n",
        "top_10_policy_channel.columns = ['Count', 'Annual_Premium']\n",
        "top_10_policy_channel"
      ],
      "metadata": {
        "id": "oFD_o5ZlZwUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "# Create a horizontal bar plot for Policy Sales Channel\n",
        "top_10_policy_channel.plot(kind='barh', figsize=(10, 6))\n",
        "\n",
        "# Set the x-axis label with bold formatting\n",
        "plt.xlabel('Count', fontweight='bold')\n",
        "\n",
        "# Set the y-axis label with bold formatting\n",
        "plt.ylabel('Policy Sales Channel', fontweight='bold')\n",
        "\n",
        "# Set the title of the plot with bold formatting\n",
        "plt.title('Top 10 Policy Sales Channels by Count', fontweight='bold')\n",
        "\n",
        "plt.grid(True, alpha=0.5)  # Add grid with alpha\n",
        "\n",
        "plt.gca().invert_yaxis()  # Invert the y-axis to display the highest count at the top\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A horizontal bar chart is a visually effective way to compare and rank the top 10 policy sales channels based on the number of policies sold and their average annual premiums."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the horizontal bar chart, we can observe the following insights:\n",
        "\n",
        "\n",
        "*  Channels 152 and 26 have the highest number of policies sold, indicating they are the most effective channels.\n",
        "*  The number of policies sold varies significantly across different channels, suggesting varying effectiveness and market penetration.\n",
        "\n",
        "*   The average annual premium varies across different channels. Some channels have higher average premiums, while others have lower ones.\n",
        "*   Factors like the target customer segment, product mix, and sales strategy of each channel might influence the average premium\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the gained insights can definitely help create a positive business impact.Some of them are:\n",
        "\n",
        "\n",
        "*    Identify underperforming channels and analyze the reasons for their low performance. Implement strategies to improve their effectiveness.\n",
        "*   Develop new products or services that cater to the specific needs of customers in different channels\n",
        "\n",
        "*   Analyze customer behavior and preferences across different channels to identify high-value segments.\n",
        "\n",
        "Negative impacts:\n",
        "\n",
        "\n",
        "*   Neglecting underperforming channels might lead to missed opportunities and reduced market share.\n",
        "*   Continuously explore and evaluate new sales channels to reduce dependence on a few top performers.\n",
        "\n",
        "*    Regularly monitor the performance of all sales channels and make necessary adjustments.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the specified columns from the DataFrame.\n",
        "# Calculating the correlation matrix between the selected columns\n",
        "columns = ['Age', 'Annual_Premium', 'Vintage']\n",
        "df_corr = df[columns].corr()\n",
        "df_corr"
      ],
      "metadata": {
        "id": "rPk8Q1iHcALo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "plt.figure(figsize=(10, 8))\n",
        "colormap = 'inferno'\n",
        "sns.heatmap(df_corr, annot=True, cmap=colormap)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A heatmap is an excellent choice for visualizing the correlation matrix between numerical variables because it provides a clear and concise representation of the relationships between each pair of variables."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the heatmap, we can observe the following insights:\n",
        "\n",
        "*  There are no strong correlations between the variables 'Age', 'Annual Premium', and 'Vintage'.\n",
        "*   The correlation coefficients are close to zero, indicating a weak or negligible linear relationship between the variables.\n",
        "\n"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#selecting specific columns\n",
        "columns = ['Age', 'Annual_Premium', 'Vintage', 'Gender']"
      ],
      "metadata": {
        "id": "w38KTDNbejRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(df[columns], hue = 'Gender', corner=True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pairplot is an excellent choice for visualizing the relationships between multiple numerical variables, especially when you want to explore potential correlations and distributions."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the pairplot, we can observe the following insights:\n",
        "\n",
        "*   There is no strong linear relationship between the variables 'Annual Premium' and 'Vintage'. The scatter plots show a random distribution of points, indicating a weak correlation.\n",
        "*   The distribution of 'Annual Premium' is right-skewed, indicating that most policies have lower premiums, with a few policies having significantly higher premiums\n",
        "\n"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The dataset's average age is 35 years old.\n",
        "*   The dataset shows an average annual premium exceeding $25,000.\n",
        "\n",
        "*   The dataset contains an equal number of male and female individuals.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the distribution of Age column is it clear that the mean age is 40 Let's use hypothesis testing to see if this statement is true.\n",
        "\n",
        "**Null Hypothesis** H₀= μ =40\n",
        "\n",
        "**Alternate Hypothesis**  Hₐ= μ ≠ 40"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "from scipy.stats import ttest_1samp\n",
        "t_statistic, p_value = ttest_1samp(df['Age'], 40)\n",
        "# Print results\n",
        "print(\"T-Statistic:\", t_statistic)\n",
        "print(f\"P-Value: {p_value}\")\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. The mean age is not equal to 40.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. The mean age is equal to 40.\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To determine statistical significance, a one-sample t-test was conducted. The t-test was chosen as the population standard deviation was unknown."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test Justification:**The one-sample t-test was selected to test the hypothesis that the population mean age is equal to 40. This test is appropriate as it allows us to compare a sample mean to a known or hypothesized population mean, especially when the population standard deviation is unknown."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Averge Annual Premium Plan is less than 30000. Let's Check this Hypothesis.\n",
        "\n",
        "**Null Hypothesis** H₀= μ <= 30000\n",
        "\n",
        "**Alternate Hypothesis**  Hₐ= μ > 30000"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import ttest_1samp\n",
        "t_statistic, p_value = ttest_1samp(df['Annual_Premium'], 30000)\n",
        "\n",
        "# For a one-tailed test, we consider the p-value for the right tail\n",
        "one_tailed_p_value = p_value / 2 if t_statistic > 0 else 1 - (p_value / 2)\n",
        "\n",
        "# Print results\n",
        "print(\"T-Statistic:\", t_statistic)\n",
        "print(f\"P-Value: {one_tailed_p_value}\")\n",
        "\n",
        "alpha = 0.05\n",
        "if one_tailed_p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. The mean annual premium is greater than 30000.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. The mean annual premium is not greater than 30000.\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A one-tailed t-test was used to calculate the p-value.\n",
        "\n"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test Justification:**The one-sample t-test was selected to test the hypothesis that the population mean annual premium is equal to 30,000. This test is appropriate as it allows us to compare a sample mean to a known or hypothesized population mean, especially when the population standard deviation is unknown. Given that we are interested in determining if the mean annual premium is significantly different from 30,000 in one direction, a one-tailed t-test was used."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check if the proportion of males and females is equal, i.e., 50%.\n",
        "\n",
        "Null Hypothesis: H₀= p = 0.5\n",
        "\n",
        "Statement: The proportion of males in the population is equal to 50%.\n",
        "\n",
        "Alternative Hypothesis: Hₐ= p ≠ 0.5\n",
        "\n",
        "Statement: The proportion of males in the population is not equal to 50%."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The formula for the z-score is given by:\n",
        "\n",
        "**z = (p̂ - p₀) / √(p₀(1-p₀)/n)**\n",
        "\n",
        "Where:\n",
        "p̂= Observed proportion of Males\n",
        "p₀= Expected proportion (e.g., 0.5 for a 50-50 split)\n",
        "n= Total no:of observations\n"
      ],
      "metadata": {
        "id": "y932JrvCrlAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import necessary library for statistical functions\n",
        "from scipy import stats\n",
        "\n",
        "# Count the number of occurrences of each gender and reset index to make it a DataFrame\n",
        "gender_count = df['Gender'].value_counts().reset_index()\n",
        "gender_count.columns = ['Gender', 'Count']\n",
        "\n",
        "# Calculate the proportion of each gender\n",
        "gender_count['Proportion'] = gender_count['Count'] / gender_count['Count'].sum()\n",
        "print(gender_count)\n",
        "print('\\n')\n",
        "\n",
        "# Extract the observed proportion of males\n",
        "p_hat = gender_count['Proportion'][0]\n",
        "\n",
        "# Define the null hypothesis proportion (e.g., 50% for a balanced split)\n",
        "p_0 = 0.5\n",
        "\n",
        "# Calculate the total number of observations\n",
        "n = gender_count['Count'].sum()\n",
        "\n",
        "# Compute the test statistic (z-score) for the observed proportion\n",
        "z_stat = (p_hat - p_0) / ( (p_0 * (1 - p_0) / n) ** 0.5 )\n",
        "\n",
        "# Calculate the p-value from the z-statistic\n",
        "p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
        "\n",
        "# Print the test statistic and p-value\n",
        "print(\"Z-Statistic:\", z_stat)\n",
        "print(f\"P-Value: {p_value}\")\n",
        "\n",
        "# Define the significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Compare p-value with alpha to determine whether to reject the null hypothesis\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. The proportion of males is not equal to 50%.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. The proportion of males is equal to 50%.\")"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test conducted is a one-sample z-test for proportions to determine if the observed proportion differs significantly from the expected proportion"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The one-sample z-test for proportions was chosen because it assesses whether the observed proportion in a sample significantly differs from a known or hypothesized population proportion, which is suitable for large sample sizes."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# Handling Missing Values & Missing Value Imputation\n",
        "# we will use our original dataset\n",
        "health_insurance_data.head()\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Checking for missing value\n",
        "health_insurance_data.isna().sum()"
      ],
      "metadata": {
        "id": "MYBpTtpn2URd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the dataset, there are no null values present. However, if null values were to exist, appropriate imputation techniques could be applied based on the distribution and type of data:\n",
        "\n",
        "\n",
        "*   Numerical Data:\n",
        "\n",
        "Normal Distribution: Mean imputation would be suitable to replace missing values.\n",
        "Skewed Distribution: Median imputation would be more appropriate to handle skewness.\n",
        "\n",
        "\n",
        "*  Categorical Data:\n",
        "\n",
        "Mode Imputation: The most frequent value (mode) would be used to replace missing categorical data.\n",
        "These imputations can be implemented using either Pandas or Scikit-learn:\n",
        "\n",
        "Using Pandas:\n",
        "data.fillna(value)\n",
        "- Using Scikit-learn:\n",
        "from sklearn.impute import SimpleImputer imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From Our Exploratory Data Analysis, we know that Annual_Premium has\n",
        "2.71% of outlier values."
      ],
      "metadata": {
        "id": "EnQrWPXk38IM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "sns.histplot(data=health_insurance_data, x='Annual_Premium', bins=25, kde=True)\n",
        "plt.title('Annual Premium Distribution with outlier')\n",
        "plt.grid(True, linestyle='--', alpha = 0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Using IQR to Identify the outliers\n",
        "Q1 = health_insurance_data['Annual_Premium'].quantile(0.25)\n",
        "Q3 = health_insurance_data['Annual_Premium'].quantile(0.75)\n",
        "# Calculate IQR\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Determine the lower and upper bounds for outliers\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Identify outliers\n",
        "outliers = health_insurance_data[(health_insurance_data['Annual_Premium'] < lower_bound) | (health_insurance_data['Annual_Premium'] > upper_bound)]\n",
        "\n",
        "# Number of outliers\n",
        "num_outliers = outliers.shape[0]\n",
        "\n",
        "print(f\"Number of Outliers: {num_outliers}\")\n"
      ],
      "metadata": {
        "id": "hjfPxzmX4pNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clip the outliers to the lower and upper bounds\n",
        "# Clip the outliers to the lower and upper bounds\n",
        "health_insurance_data['Annual_Premium'] = health_insurance_data['Annual_Premium'].clip(lower=lower_bound, upper=upper_bound)\n",
        "\n"
      ],
      "metadata": {
        "id": "xxgfcl165FC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Handling Outliers & Outlier treatments\n",
        "sns.histplot(data=health_insurance_data, x='Annual_Premium', bins=25, kde=True)\n",
        "plt.title('Annual Premium Distribution without outlier')\n",
        "plt.grid(True, linestyle='--', alpha = 0.5)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GBJ8Xhzz5UsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation**: Our dataset contains 10320 outliers, representing about 2.71% of the total data. To handle these outliers, we've employed a clipping technique, which caps extreme values within a defined range to preserve data integrity.\n",
        "It's important to note that outlier treatment strategies vary depending on the specific context and the underlying causes of the outliers. While clipping was used in this case, alternative methods like winsorizing (capping extreme values at a certain percentile) or imputation (replacing outliers with estimated values) could be considered in different scenarios."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "2SK6Ri-Ujc9p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Do you think the dataset is imbalanced? Explain Why?**\n",
        "\n",
        "The dataset exhibits a significant class imbalance, with the majority class (Class 0) comprising 267,700 samples and the minority class (Class 1) comprising 37,187 samples. This imbalance ratio of approximately 7.2:1 poses challenges in model training and evaluation.\n",
        "\n"
      ],
      "metadata": {
        "id": "fn8nkxXmkc70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Changing data types of Region and Policy Sales Channel\n",
        "health_insurance_data['Region_Code'] = health_insurance_data['Region_Code'].astype('int').astype('str')\n",
        "health_insurance_data['Policy_Sales_Channel'] =health_insurance_data['Policy_Sales_Channel'].astype('int').astype('str')\n"
      ],
      "metadata": {
        "id": "w_drKzJ1jy8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "health_insurance_data.drop(columns=['id'], inplace=True)"
      ],
      "metadata": {
        "id": "UKEjXaBjkCgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = health_insurance_data.drop(columns=['Response'])\n",
        "y = health_insurance_data['Response']"
      ],
      "metadata": {
        "id": "MQrIV7JxkIz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y.value_counts().reset_index()"
      ],
      "metadata": {
        "id": "Tq-Po1bZk5j2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Handling Imbalanced Dataset (If needed)\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Initialize RandomOverSampler\n",
        "oversample = RandomOverSampler(random_state=42)\n",
        "\n",
        "# Apply oversampling to training data\n",
        "X, y  = oversample.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "zfttbgh5lC59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape\n"
      ],
      "metadata": {
        "id": "Cwl4doEPlHPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)**?\n",
        "\n",
        "To address the imbalance in the dataset, RandomOverSampler was used. This technique balances the dataset by randomly duplicating samples from the minority class until both classes are equally represented."
      ],
      "metadata": {
        "id": "7YFEtAKglP2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Data Splitting**"
      ],
      "metadata": {
        "id": "aKg3AE26hwUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To avoid data leakage, the dataset should be split into training and test sets prior to preprocessing. Encoding and scaling should be performed independently on each set to ensure that the model is evaluated on unseen data."
      ],
      "metadata": {
        "id": "rUbWyJDCiH5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "dGXKYOtphvba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What data splitting ratio have you used and why?**\n",
        "\n",
        "To optimize the model's generalization performance, I implemented an 80-20 train-test split, allocating 80% of the data for training and 20% for validation.\n",
        "\n"
      ],
      "metadata": {
        "id": "vtcqGXUcdMZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "4yXKUe84l0HT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders\n"
      ],
      "metadata": {
        "id": "RnhOHZChlzD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "health_insurance_data.info()"
      ],
      "metadata": {
        "id": "fYP2K4r4l6Mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "# Identify categorical features with high cardinality (more than 30 unique values)\n",
        "cat_features_high_car = [column for column in health_insurance_data.columns if health_insurance_data[column].dtype == 'object' and len(health_insurance_data[column].unique()) > 30]\n",
        "\n",
        "# Identify categorical features with low cardinality (30 or fewer unique values)\n",
        "cat_features = [column for column in health_insurance_data.columns if health_insurance_data[column].dtype == 'object' and len(health_insurance_data[column].unique()) <= 30]\n",
        "\n",
        "# Import BinaryEncoder for high-cardinality features and necessary transformers from sklearn\n",
        "from category_encoders import BinaryEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Initialize BinaryEncoder for high-cardinality categorical features\n",
        "encoder = BinaryEncoder(cols=cat_features_high_car)\n",
        "\n",
        "# Apply Binary Encoding to the training and test data\n",
        "\n",
        "X_train = encoder.fit_transform(X_train)\n",
        "X_test = encoder.transform(X_test)\n",
        "\n",
        "# Initialize OneHotEncoder for low-cardinality categorical features\n",
        "onehotencoder = OneHotEncoder(drop='first', sparse_output=False, dtype=np.int64)\n",
        "\n",
        "# Create a ColumnTransformer to apply OneHotEncoder to low-cardinality features\n",
        "preprocessor = ColumnTransformer(\n",
        "    [\n",
        "        (\"OneHotEncoder\", onehotencoder, cat_features),  # Apply OneHotEncoder to low-cardinality features\n",
        "    ], remainder='passthrough'  # Pass through other columns without transformation\n",
        ")\n",
        "\n",
        "# Apply One-Hot Encoding to low-cardinality features and pass through high-cardinality features\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)\n",
        "\n",
        "# Convert the transformed arrays back to DataFrames with feature names\n",
        "X_train = pd.DataFrame(X_train, columns=preprocessor.get_feature_names_out())\n",
        "X_test = pd.DataFrame(X_test, columns=preprocessor.get_feature_names_out())\n",
        "\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "Y2zql0sxhDHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To handle categorical variables, One-Hot Encoding was used for nominal columns like 'Gender' and 'Vehicle Age', while Binary Encoding was applied to high-cardinality columns like 'Region Code' and 'Policy Sales Channel' to reduce feature dimensionality."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ID column is also dropped cause it does not have much predictive power"
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*  Age: Age can influence insurance needs due to varying risk profiles associated with different age groups.\n",
        "*   Driving License: The possession of a valid driving license is a prerequisite for vehicle insurance.\n",
        "\n",
        "*   Prior Insurance: Customers with a history of insurance may have different preferences and behaviors compared to new customers.\n",
        "*   Vehicle Age: Older vehicles may require specific insurance coverage, affecting customer interest.\n",
        "\n",
        "*  Vehicle Damage History: Previous damage claims can influence the customer's perception of insurance and their willingness to purchase additional coverage\n",
        "*   Premium Cost: The affordability of the insurance premium is a crucial determinant of customer interest.\n",
        "\n",
        "*   Sales Channel: The effectiveness of different sales channels in reaching customers can vary.\n",
        "*   Customer Tenure: The duration of a customer's relationship with the company can influence their loyalty and propensity to purchase additional products.\n",
        "\n",
        "*  Region_Code: The region where the customer resides could affect their insurance needs and interest levels due to regional differences in insurance practices and policies.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data transformation is crucial for improving the performance of machine learning models, including those used for health insurance cross-sell prediction. Key transformations to consider include:\n",
        "\n",
        "1. Handling Missing Values: Imputation or removal of missing values.\n",
        "2. Feature Scaling: Normalization or standardization of numerical features.\n",
        "3. Categorical Variable Encoding: One-hot encoding or label encoding.\n",
        "The specific techniques employed should be based on the characteristics of the dataset and the goals of the analysis.\n"
      ],
      "metadata": {
        "id": "JMAeclzIgfJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "# Scaling your data\n",
        "num_columns = [column for column in X_train.columns if X_train[column].dtype != \"object\" and len(X_train[column].unique()) > 10]\n",
        "\n",
        "# Import StandardScaler from sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform the numerical columns\n",
        "X_train[num_columns] = scaler.fit_transform(X_train[num_columns])\n",
        "\n",
        "# Transform the numerical columns of the test data using the fitted scaler\n",
        "X_test[num_columns] = scaler.transform(X_test[num_columns])\n"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Save the original feature column names\n",
        "features_columns = X_train.columns\n",
        "\n",
        "# Convert the DataFrame to a NumPy array\n",
        "# X_train = X_train.values\n",
        "\n",
        "# Convert the test set DataFrame to a NumPy array\n",
        "# X_test = X_test.values\n"
      ],
      "metadata": {
        "id": "UFvfyhbfpFY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "StandardScaler was used to normalize features, ensuring they have a mean of 0 and a standard deviation of 1. This standardizes the scale of features, improving model performance"
      ],
      "metadata": {
        "id": "BRxItlAUpU8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset includes 23 features with minimal correlation, suggesting that dimensionality reduction techniques like PCA may not be necessary. Feature selection can be more effective in identifying and retaining important features.\n",
        "\n"
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dimensionality reduction was not necessary for this dataset."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, ConfusionMatrixDisplay, RocCurveDisplay\n"
      ],
      "metadata": {
        "id": "waY0cqAyqECk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "model_1 = LogisticRegression(n_jobs=-1)\n",
        "# Fit the Algorithm\n",
        "model_1.fit(X_train, y_train)\n",
        "# Predict on the model\n",
        "y_pred = model_1.predict(X_test)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "uEHI7_ZxqNUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Let's Create a DF for evaluation matric score, (accuracy, recall, precision and F1-Score)\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "evaluation_dict = {\n",
        "    'Model Name': 'model_1',\n",
        "    'Model Type': 'Logistic Regression',\n",
        "    'Accuracy': accuracy_score(y_test, y_pred),\n",
        "    'Recall': recall_score(y_test, y_pred),\n",
        "    'Precision': precision_score(y_test, y_pred),\n",
        "    'F1-Score': f1_score(y_test, y_pred)\n",
        "}\n",
        "\n",
        "evaluation_df = pd.DataFrame(evaluation_dict, index=[0])\n",
        "evaluation_df"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "ConfusionMatrixDisplay.from_estimator(model_1, X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2uKGCl6uqb8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "RocCurveDisplay.from_estimator(model_1, X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R0Bg_e2hqiT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:** A logistic regression model, a popular choice for binary classification tasks, has been trained on the training data. This model is particularly effective when the relationship between features and the target variable can be approximated by a linear function. The trained model is now being applied to the unseen test data to assess its predictive performance."
      ],
      "metadata": {
        "id": "M4nc-2Wrq-0A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n"
      ],
      "metadata": {
        "id": "OI92dPL0rRTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the hyperparameter grid (consider reducing grid size if needed)\n",
        "params = {\n",
        "    'C':  [0.001, 0.01, 0.1, 1, 10],  # Reduce grid size for example\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "# Set up GridSearchCV with parallelization and early stopping (if applicable)\n",
        "model_1_hyper = GridSearchCV(model_1, params, cv=2, scoring='accuracy', n_jobs=-1,\n",
        "                             # Consider adding early_stopping='auto' if supported by model_1\n",
        "                             )\n",
        "\n",
        "# Improve data loading efficiency if necessary (code not provided)\n",
        "\n",
        "# Fit the model with hyperparameter optimization\n",
        "model_1_hyper.fit(X_train, y_train)\n",
        "\n",
        "# Print best hyperparameters\n",
        "print(\"Best Hyperparameters:\", model_1_hyper.best_params_)\n",
        "\n",
        "# Make predictions on the test set\n",
        "model_1_hyper_pred = model_1_hyper.predict(X_test)"
      ],
      "metadata": {
        "id": "9fpzrvrtsLyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, model_1_hyper_pred))"
      ],
      "metadata": {
        "id": "xGOHUFgGrnIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used RandomizedSearchCV for hyperparameter optimization. This technique was chosen because it efficiently samples a specified number of hyperparameter combinations randomly, making it less computationally expensive than exhaustive methods like grid search."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Appedn the evaluation of hypertunned model to evaluation_df\n",
        "model_1_hyper_dict = {\n",
        "    'Model Name': 'model_1_hyper',\n",
        "    'Model Type': 'Logistic Regression',\n",
        "    'Accuracy': accuracy_score(y_test, model_1_hyper_pred),\n",
        "    'Recall': recall_score(y_test, model_1_hyper_pred),\n",
        "    'Precision': precision_score(y_test, model_1_hyper_pred),\n",
        "    'F1-Score': f1_score(y_test, model_1_hyper_pred)\n",
        "}\n",
        "\n",
        "evaluation_df = pd.concat([evaluation_df, pd.DataFrame([model_1_hyper_dict])], ignore_index=True)\n",
        "evaluation_df"
      ],
      "metadata": {
        "id": "GtksIbtMcYeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "RocCurveDisplay.from_estimator(model_1_hyper, X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BZ1w4XWXcxgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ML Model - 2 Implementation\n",
        "model_2 = DecisionTreeClassifier()\n",
        "\n",
        "# Fit the Algorithm\n",
        "model_2.fit(X_train, y_train)\n",
        "# Predict on the model\n",
        "model_2_pred = model_2.predict(X_test)"
      ],
      "metadata": {
        "id": "wLQUvGxXc1jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, model_2_pred))"
      ],
      "metadata": {
        "id": "LX9pL5HIc7EA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_2_dict = {\n",
        "    'Model Name': 'model_2',\n",
        "    'Model Type': 'Decision Tree',\n",
        "    'Accuracy': accuracy_score(y_test, model_2_pred),\n",
        "    'Recall': recall_score(y_test, model_2_pred),\n",
        "    'Precision': precision_score(y_test, model_2_pred),\n",
        "    'F1-Score': f1_score(y_test, model_2_pred)\n",
        "}\n",
        "\n",
        "evaluation_df = pd.concat([evaluation_df, pd.DataFrame([model_2_dict])], ignore_index=True)\n",
        "evaluation_df"
      ],
      "metadata": {
        "id": "EoeDx8y8dVxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "ConfusionMatrixDisplay.from_estimator(model_2, X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "RocCurveDisplay.from_estimator(model_2, X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0_1CqSQzdh4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "param_distributions = {\n",
        "    'max_depth': [10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 5, 10],\n",
        "    'max_features': ['auto', 'sqrt','log2']\n",
        "}\n",
        "\n",
        "# Set up the RandomizedSearchCV\n",
        "model_2_hyper = RandomizedSearchCV(model_2, param_distributions, cv=3, random_state=42, n_iter=80,scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Fit the model\n",
        "model_2_hyper.fit(X_train, y_train)\n",
        "# Predict on the model\n",
        "model_2_hyper_pred = model_2_hyper.predict(X_test)\n",
        "\n",
        "print(\"Best Hyperparameters:\", model_2_hyper.best_params_)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, model_2_hyper_pred))"
      ],
      "metadata": {
        "id": "guUQdoqed4li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I opted for RandomizedSearchCV to efficiently explore the hyperparameter space, reducing computational cost compared to grid search."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According To the above Evaluation Metric hart, the model's performance is quite strong, with an accuracy of 90.06%, precision of 89.04%, recall of 99.84%, and an F1-score of 0.9424. This indicates that the model is both accurate and reliable in its predictions."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_hyper_dict = {\n",
        "    'Model Name': 'model_2_hyper',\n",
        "    'Model Type': 'Decision Tree',\n",
        "    'Accuracy': accuracy_score(y_test, model_2_hyper_pred),\n",
        "    'Recall': recall_score(y_test, model_2_hyper_pred),\n",
        "    'Precision': precision_score(y_test, model_2_hyper_pred),\n",
        "    'F1-Score': f1_score(y_test, model_2_hyper_pred)\n",
        "}\n",
        "\n",
        "evaluation_df = pd.concat([evaluation_df, pd.DataFrame([model_2_hyper_dict])], ignore_index=True)\n",
        "evaluation_df"
      ],
      "metadata": {
        "id": "uOWM3sUPzAy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "RocCurveDisplay.from_estimator(model_2_hyper, X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p9uP9QZ8zGT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting Confusion Matrix\n",
        "ConfusionMatrixDisplay.from_estimator(model_2_hyper, X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N-AADmMJzMD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the confusion matrix and evaluation metrics, the model appears to be performing quite well. It's accurately identifying positive and negative cases, with a strong emphasis on recall. This could be particularly beneficial in scenarios where missing positive cases is more costly than false positives."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ML Model - 3 Implementation\n",
        "model_3 = RandomForestClassifier()\n",
        "# Fit the Algorithm\n",
        "model_3.fit(X_train, y_train)\n",
        "# Predict on the model\n",
        "model_3_pred = model_3.predict(X_test)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, model_3_pred))"
      ],
      "metadata": {
        "id": "yrPebqcI07jJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_3_dict = {\n",
        "    'Model Name': 'model_3',\n",
        "    'Model Type': 'Random Forest',\n",
        "    'Accuracy': accuracy_score(y_test, model_3_pred),\n",
        "    'Recall': recall_score(y_test, model_3_pred),\n",
        "    'Precision': precision_score(y_test, model_3_pred),\n",
        "    'F1-Score': f1_score(y_test, model_3_pred)\n",
        "}\n",
        "\n",
        "evaluation_df = pd.concat([evaluation_df, pd.DataFrame([model_3_dict])], ignore_index=True)\n",
        "evaluation_df\n"
      ],
      "metadata": {
        "id": "hSfpO_cx1bXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "RocCurveDisplay.from_estimator(model_3, X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_estimator(model_3, X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "seThYcxP1qxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "ref_params = {\"min_samples_split\": [2, 3, 5, 8],\n",
        "             \"n_estimators\": [64,100,128,200]}\n",
        "# Fit the Algorithm\n",
        "model_3_hyper = RandomizedSearchCV(model_3, ref_params, cv=2, random_state=42, n_iter=5,scoring='accuracy', n_jobs=-1)\n",
        "model_3_hyper.fit(X_train, y_train)\n",
        "# Predict on the model\n",
        "model_3_hyper_pred = model_3_hyper.predict(X_test)\n",
        "\n",
        "print(\"Best Hyperparameters:\", model_3_hyper.best_params_)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, model_3_hyper_pred))"
      ],
      "metadata": {
        "id": "aWjms1HR8vlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I opted for RandomizedSearchCV to efficiently explore the hyperparameter space, reducing computational cost compared to grid search."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_hyper_dict = {\n",
        "    'Model Name': 'model_3_hyper',\n",
        "    'Model Type': 'Random Forest',\n",
        "    'Accuracy': accuracy_score(y_test, model_3_hyper_pred),\n",
        "    'Recall': recall_score(y_test, model_3_hyper_pred),\n",
        "    'Precision': precision_score(y_test, model_3_hyper_pred),\n",
        "    'F1-Score': f1_score(y_test, model_3_hyper_pred)\n",
        "}\n",
        "\n",
        "evaluation_df = pd.concat([evaluation_df, pd.DataFrame([model_3_hyper_dict])], ignore_index=True)\n",
        "evaluation_df"
      ],
      "metadata": {
        "id": "mNq9AHq3_OjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Roc Curve\n",
        "RocCurveDisplay.from_estimator(model_3_hyper, X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mLzwxUhQ_V41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Confusion Matrix\n",
        "ConfusionMatrixDisplay.from_estimator(model_3_hyper, X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VPbZg2US_drT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "*   Logistic Regression:\n",
        "\n",
        "Model_1: Achieved an accuracy of 0.7854, recall of 0.9629, precision of 0.7110, and F1-score of 0.8179.\n",
        "\n",
        "Model_1_hyper: After hyperparameter tuning, the model's performance slightly decreased in precision and F1-score, while recall increased slightly.\n",
        "\n",
        "*   Decision Tree:\n",
        "\n",
        "Model_2: Achieved an accuracy of 0.9443, recall of 0.9986, precision of 0.9009, and F1-score of 0.9472.\n",
        "\n",
        "Model_2_hyper: After hyperparameter tuning, the model's performance decreased in all metrics.\n",
        "\n",
        "\n",
        "\n",
        "*  Random Forest:\n",
        "\n",
        "Model_3: Achieved an accuracy of 0.9492, recall of 0.9983, precision of 0.9091, and F1-score of 0.9516.\n",
        "\n",
        "Model_3_hyper: After hyperparameter tuning, the model's performance improved slightly in all metrics.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Overall, the Random Forest model (Model_3_hyper) appears to be the best-performing model based on the provided metrics. It has the highest F1-score, indicating a good balance between precision and recall."
      ],
      "metadata": {
        "id": "3NtPHnUF_1-H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Metrics for Positive Business Impact**\n",
        "\n",
        "\n",
        "*   Precision: To reduce wasted marketing efforts and improve targeting accuracy.\n",
        "*   Recall: To ensure the model identifies as many interested customers as possible.\n",
        "\n",
        "*  F1 Score: To balance precision and recall, providing an overall measure of performance.\n",
        "*  ROC-AUC: To evaluate the model’s ability to distinguish between positive and negative classes across different thresholds.\n",
        "\n",
        "\n",
        "* Confusion Matrix: To identify specific prediction errors and guide improvements.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Drop the 'Model Type' column\n",
        "evaluation_df.drop(columns=['Model Type'], inplace=True)\n",
        "\n",
        "# Melt the dataframe for plotting\n",
        "df_melted = evaluation_df.melt(id_vars=['Model Name'], var_name='Metric', value_name='Value')\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Model Name', y='Value', hue='Metric', data=df_melted, palette='mako')\n",
        "\n",
        "# Add a horizontal line at 0.90\n",
        "plt.axhline(y=0.90, color='red', linestyle='--', linewidth=2)\n",
        "\n",
        "# Titles and labels\n",
        "plt.title('Model Performance Metrics')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Value')\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.legend(title='Metric', bbox_to_anchor=(1, 1), loc='upper left')\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W5JaeqOREbFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chosen Model: Random Forest Model(Model 3)\n",
        "\n",
        "Reasons For choosing this model:\n",
        "\n",
        "\n",
        "*   Accuaracy: Model 3 has the highest accuracy (0.949469) among the models\n",
        "*  Recall: It achieves a high recall (0.998328), ensuring that it identifies nearly all interested customers.\n",
        "\n",
        "\n",
        "*   Precision:  It has strong precision (0.909589), indicating effective targeting of interested customers.\n",
        "*   F1-Score:  Model 3 has the highest F1-Score (0.951895), reflecting a good balance between precision and recall. Overall, Model 3 offers the best combination of high accuracy, recall, precision, and F1-Score, making it the most effective model for predicting customer interest in the vehicle insurance cross-sell offer.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1p70TPa5EuZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "feature_df = pd.DataFrame({'feature_name ': X_train.columns, 'feature_importance': model_3.feature_importances_})"
      ],
      "metadata": {
        "id": "ePWYJF5sGc30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "feature_df.sort_values(by='feature_importance', ascending=False, inplace=True)\n",
        "feature_df"
      ],
      "metadata": {
        "id": "bkPQikO8GhGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='feature_importance', y='feature_name ', data=feature_df, palette='mako')\n",
        "plt.title('Feature Importance')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Features')\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "34ToL0GHGsZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Random Forest model was selected for this project. This ensemble learning technique combines multiple decision trees to improve predictive accuracy and reduce overfitting."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Importance:**\n",
        "This plot visualizes the relative importance of each feature in the Random Forest model. Features with higher importance scores contribute more to the model's predictions.\n",
        "\n",
        "Based on the plot, the following features appear to be most important:\n",
        "\n",
        "\n",
        "1.   remainder_Vintage: This likely represents the duration of the customer's insurance policy. Main business implication is that  Longer-term customers might be more loyal and less likely to churn. So we should Understand their needs and preferences so that we can retain them.\n",
        "\n",
        "2.   OneHotEncoder_Vehicle_Damage_Yes: This indicates whether the vehicle has had previous damage.\n",
        "\n",
        "   Business Implication: Customers with damaged vehicles might require specific insurance policies or additional coverage. Tailoring offerings to their needs can increase customer satisfaction and retention.\n",
        "\n",
        "\n",
        "3.   remainder_Annual_Premium: This likely represents the age of the policyholder.\n",
        "\n",
        "   Business Implication: Different age groups have varying insurance needs and risk profiles. Tailoring products and marketing strategies to specific age groups can improve customer engagement.\n",
        "\n",
        "These features provide valuable insights into customer behavior and significantly influence the model's predictions.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qC7XccEyIABt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Save the File\n",
        "# import joblib\n",
        "import joblib\n",
        "\n",
        "\n",
        "path = \"/content/drive/MyDrive/Capstone Project 6\"\n",
        "\n",
        "\n",
        "# Save Model\n",
        "joblib.dump(model_3, path + \"/model_3.pkl\")"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data.\n",
        "path = \"/content/drive/MyDrive/Capstone Project 6\"\n",
        "load_model = joblib.load(path + \"/model_3.pkl\")"
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_pred = load_model.predict(X_test)\n",
        "print(f'Accuaracy: {accuracy_score(y_test, load_pred)}')\n",
        "print(f'Recall: {recall_score(y_test, load_pred)}')\n",
        "print(f'Precision: {precision_score(y_test, load_pred)}')\n",
        "print(f'F1-Score: {f1_score(y_test, load_pred)}')"
      ],
      "metadata": {
        "id": "I_t2qOiQNCvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The developed Random Forest model demonstrated strong predictive performance, achieving an accuracy of 94.89%, recall of 99.82%, precision of 90.88%, and an F1-score of 95.14%. These results indicate that the model is effective in correctly identifying positive cases while maintaining a balance between precision and recall."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}